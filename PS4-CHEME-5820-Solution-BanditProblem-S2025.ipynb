{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b0930b5-bb8a-4e6d-acf6-1c43765338af",
   "metadata": {},
   "source": [
    "# PS4: A Contextual Stochastic Bandit Personal Shopper\n",
    "Fill me in\n",
    "\n",
    "### Background: Consumer choice problems\n",
    "Imagine that a consumer must choose $m$ possible goods (where each good is in a category with $k$ alternatives) $\\mathbf{n} = \\left\\{n_{1},n_{2},\\dots,n_{m}\\right\\}$, where $n_{j}\\in\\mathbb{R}_{\\geq{0}}$ is the quantity of good $j$ chosen, i.e., the consumer must choose a non-negative quantity of any good. Different combinations of the $m$-goods are _scored_, i.e., how much benefit or happiness they ellicit, using a utility function $U:\\mathbb{R}^{m}\\rightarrow\\mathbb{R}$. In this case, let's assume our consumer uses a linear utility model:\n",
    "$$\n",
    "\\begin{align*}\n",
    "U(\\mathbf{n}) = \\sum_{i=1}^{m}n_{i}\\cdot{\\gamma_{i}}\n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\gamma_{i}$ denote _user sentiment_ parameters: if $\\gamma_{i}>{0}$, then good $i$ is _preferred_ (an increase in good $n_{i}$ all else held the same, increases the utility), otherwise if $\\gamma_{i}<{0}$ then good $i$ is _not preferred_ (an increase in good $n_{i}$, all else held the same, gives a lower utility). Finally, the choice of goods $n_{1},\\dots,n_{m}$ is subject to a budget constraint (and potentially other constraints) that limits the total amount of money the consumer can spend on goods:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\sum_{i=1}^{m}n_{i}\\cdot{C}_{i} \\leq B\n",
    "\\end{align*}\n",
    "$$\n",
    "where $C_{i}$ is the unit cost of good $i$, and $B$ is the total budget the consumer can spend. The objective of a consumer is to maximize the utility of their choice (the combination of $m$ goods) subject to a budget constraint. We could solve this problem using [Linear Programming](https://en.wikipedia.org/wiki/Linear_programming), however, let's try to do this as a contextual stochastic bandit problem where the agent (personal shopper) learns to recommend a combination of goods over time based on user feedback.\n",
    "\n",
    "## Background: Stochastic Multi-Armed Bandits\n",
    "In the stochastic multi-armed bandit problem, an agent must choose an action $a$ from the set of all possible actions $\\mathcal{A}$, where $\\dim\\mathcal{A} = K$ during each round $t = 1,2,\\dots, T$ of a decision task. The agent chooses action $a\\in\\mathcal{A}$ and receives a reward $r_{a}$ from the environment, where $r_{a}$ is sampled from some (unknown) distribution $\\mathcal{D}_{a}$.\n",
    "\n",
    "For $t = 1,2,\\dots,T$:\n",
    "1. _Aggregator_: The agent picks an action $a_{t} \\in \\mathcal{A}$ at time time $t$. How the agent makes this choice is one of the main differences between the different algorithms for solving this problem. \n",
    "2. _Adversary_: The agent implements action $a_{t}$ and receives a (random) reward $r_{a}\\sim\\mathcal{D}_{a}$ where $r_{t}\\in\\left[0,1\\right]$. The distribution $\\mathcal{D}_{a}$ is only known to the adversary.\n",
    "3. The agent updates its _memory_ with the reward and continues to the next decision task. \n",
    "\n",
    "The agent is interested in learning the mean of the reward distribution of each arm, $\\mu(a) = \\mathbb{E}\\left[r_{t}\\sim\\mathcal{D}_{a}\\right]$, by experimenting against the world (adversary). \n",
    "* __Goal__: The goal of the agent is to maximize the total reward. However, the goal of the algorithm designer is to minimize the _regret_ of the algorithm that the agent uses to choose $a\\in\\mathcal{A}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb11a8d-98f9-44b7-b47f-10eedaeae119",
   "metadata": {},
   "source": [
    "## Task 1: Setup, Data, and Prerequisites\n",
    "We set up the computational environment by including the `Include.jl` file, loading any needed resources, such as sample datasets, and setting up any required constants. \n",
    "* The `Include.jl` file also loads external packages, various functions that we will use in the exercise, and custom types to model the components of our problem. It checks for a `Manifest.toml` file; if it finds one, packages are loaded. Other packages are downloaded and then loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8833f121-3387-4477-9830-24115c8abbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03d3008-fda1-4172-8af4-fc177c949a15",
   "metadata": {},
   "source": [
    "First, let's build the `world(...)` function. \n",
    "* This function takes the $m$-dimensional action vector `a::Array{Int64,1}` where the elements of `a::Array{Int64,1}` are the indexes of the goods chosen from each categories, the amount of each good selected from each category from our agent is in the `n::Dict{Int,Array{Float64,1}}` dictionary, and returns the reward (utility) $r\\sim\\mathcal{D}_{a}$. associated with selecting this action. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51eead03-b084-4d87-8560-b41fb212c6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "function world(a::Vector{Int64}, n::Dict{Int,Array{Float64,1}}, context::MyBanditConsumerContextModel)::Float64\n",
    "\n",
    "    # initialize -\n",
    "    γ = context.γ; # consumer preferences (unknown to bandits)\n",
    "    σ = context.σ; # noise in utility calculation (unknown to bandits)\n",
    "    B = context.B; # max budget (unknown to bandits)\n",
    "    C = context.C; # unit costs of goods (unknown to bandits)\n",
    "    λ = context.λ; # sensitivity to the budget\n",
    "    Z = context.Z; # noise model\n",
    "    ϵ = 0.001; # min unit required\n",
    "    number_of_categories = context.m; # number of categories\n",
    "\n",
    "    # compute the reward for this choice -\n",
    "    Ū = 1.0;\n",
    "    BC = 0.0;\n",
    "    for i ∈ 1:number_of_categories\n",
    "        \n",
    "        # what action in category i, did we just take?\n",
    "        aᵢ = a[i]; # this is which good to purchase in category i -\n",
    "        nᵢ = max(ϵ, n[i][aᵢ]); # this is how much of good i to purchase (must be geq ϵ)\n",
    "        Cᵢ = C[i][aᵢ]; # cost of chosen good in category i\n",
    "        γᵢ = γ[i][aᵢ]; # preference of good in category i\n",
    "        σᵢ = (σ[i][aᵢ]); # standard dev for good i\n",
    "        Zᵢ = Z[i]; # noise model\n",
    "   \n",
    "        # update the utility -\n",
    "        Ū += γᵢ*(nᵢ + σᵢ*rand(Zᵢ)); # compute the utility for this good, with noise\n",
    "        \n",
    "        # constraints and noise \n",
    "        BC += nᵢ*Cᵢ; # compute the budget constraint -\n",
    "    end\n",
    "\n",
    "    # compute the budget constraint violation -\n",
    "    U = Ū - λ*max(0.0, (BC-B))^2; # use a penalty method to capture budget constraint\n",
    "\n",
    "    # return the reward -\n",
    "    return U;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c57990a",
   "metadata": {},
   "source": [
    "Next, let's build an algorithm model that we'll use to reason about the world, i.e., a model of our agent's decision making process.  we've modified the $\\epsilon$-greedy algorithm to work with our contextual category-based bandit problem. The algorithm will now take into account the context provided by [the `MyBanditConsumerContextModel` model](src/Types.jl) and category-based actions when selecting actions.\n",
    "\n",
    "#### Epsilon-Greedy with Categories Algorithm\n",
    "In the _epsilon-greedy_ algorithm, the agent chooses the best arm with probability $1-\\epsilon$ and a random arm with probability $\\epsilon$. This approach balances exploration and exploitation by allowing the agent to explore different arms while also exploiting the best-known arm based on past rewards. The parameter $\\epsilon$ controls the exploration rate: a higher value means more exploration, while a lower value means more exploitation.\n",
    "\n",
    "* While [Slivkins](https://arxiv.org/abs/1904.07272) doesn't give a reference for the $\\epsilon$-greedy algorithm, other sources point to (at least in part) to [Thompson and Thompson sampling, proposed in 1933 in the context of drug trials](https://arxiv.org/abs/1707.02038). Thus, the $\\epsilon$-greedy algorithm, considered a classic algorithm in the multi-armed bandit literature. The algorithm is simple yet effective, making it a popular choice for many practical applications.\n",
    "\n",
    "The agent has $K$ arms (choices), $\\mathcal{A} = \\left\\{1,2,\\dots,K\\right\\}$, and the total number of rounds is $T$. The agent uses the following algorithm to choose which arm to pull (which action to take) during each round:\n",
    "\n",
    "For $t = 1,2,\\dots,T$:\n",
    "1. _Initialize_: Roll a random number $p\\in\\left[0,1\\right]$ and compute a threshold $\\epsilon_{t}\\sim{t}^{-1/3}$. Note, in other sources, $\\epsilon$ is a constant, not a function of $t$.\n",
    "2. _Exploration_: If $p\\leq\\epsilon_{t}$, choose a random (uniform) arm $a_{t}\\in\\mathcal{A}$. Execute the action $a_{t}$ and receive a reward $r_{t}$ from the _adversary_ (nature). \n",
    "3. _Exploitation_: Else if $p>\\epsilon_{t}$, choose action $a^{\\star}$ (action with the highest average reward so far, the greedy choice). Execute the action $a^{\\star}_{t}$ and recieve a reward $r_{t}$ from the _adversary_ (nature).\n",
    "4. Update list of rewards for $a_{t}\\in\\mathcal{A}$\n",
    "\n",
    "__Theorem__: The epsilon-greedy algowithm with exploration probability $\\epsilon_{t}={t^{-1/3}}\\cdot\\left(K\\cdot\\log(t)\\right)^{1/3}$ achives a regret bound of $\\mathbb{E}\\left[R(t)\\right]\\leq{t}^{2/3}\\cdot\\left(K\\cdot\\log(t)\\right)^{1/3}$ for each round $t$.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "812348cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = let\n",
    "\n",
    "    # initialize -\n",
    "    K = Dict{Int64,Int64}(); # arms dictionary\n",
    "    n = Dict{Int64, Array{Float64,1}}() # items dictionary\n",
    "\n",
    "    # How many alternatives (arms) do we have in category?\n",
    "    K[1] = 3; # category 1 has three possible choices\n",
    "    K[2] = 6; # categorty 2 has six possible choices\n",
    "    K[3] = 4; # category 4 has four possible choices\n",
    "\n",
    "    # how many items would we purchase *if* we choose alternative i in category j?  \n",
    "    n[1] = [1.0, 1.0, 1.0]; # category 1\n",
    "    n[2] = [2.0, 2.0, 2.0, 2.0, 2.0, 2.0]; # category 2\n",
    "    n[3] = [3.0, 3.0, 3.0, 3.0]; # category 3\n",
    "    \n",
    "    # build model -\n",
    "    algorithm = build(MyEpsilonGreedyAlgorithmModel, (\n",
    "        K = K, # arms dictionary\n",
    "        n = n, # items dictionary\n",
    "    ));\n",
    "\n",
    "    # return the algorithm -\n",
    "    algorithm;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59e7284",
   "metadata": {},
   "source": [
    "__Constants__: Finally, let's set some constants we'll use in the subsequent tasks. See the comment beside the value for a description of what it is, its permissible values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3943a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10000; # number of rounds for each decision task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47b3cec-9420-499f-85be-d9f1bfa017bc",
   "metadata": {},
   "source": [
    "## Task 2: Build the Context Models\n",
    "In this task, we will build several models of the contextual information that will be used to inform the agent's recomendations. These models, which are [instances of the `MyBanditConsumerContextModel` type](src/Types.jl) holds various parameters that will be used in the `world(...)` funtion that we developed above. \n",
    "* _Hmmm. Why use a different model for contextual data_? We use a separate model for the contextual information because it allows us to encapsulate all the relevant parameters and settings in one place. This makes it easier to manage and modify the parameters as needed, without having to change the core logic of the `world(...)` function. Additionally, it allows us to easily pass around context models to other parts of our codebase that may need it.\n",
    "* _What does this represent_? The contextual information in the `MyBanditConsumerContextModel` represents the parameters that will be used to score the utility of the goods chosen by the agent. This includes user sentiment parameters, budget constraints, and other relevant information that will help the agent make informed decisions about which goods to recommend.\n",
    "\n",
    "Let's build the following contextual models:\n",
    "* __Case 1: Unlimited budget, uniform positive sentiment__: This model assumes that the consumer has an unlimited budget ($\\lambda = 0$) and uniform positive sentiment across all goods. This means that the consumer is equally likely to choose any good in each category, and there are no constraints on the amount of each good that can be selected. \n",
    "* __Case 2: Limited budget, positive sentiment__: This model assumes that the consumer has a limited budget $\\lambda>0$ and positive sentiment (but not neccesarily uniform) towards goods. This means that the consumer is more likely to choose goods that they have a positive sentiment towards, and there are constraints on the amount of each good that can be selected based on the budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b47292ca-6238-44aa-bc24-80bc82b5fba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_no_budget_context = let\n",
    "\n",
    "    # initialize -\n",
    "    γ = Dict{Int,Vector{Float64}}(); # consumer preferences (unknown to bandits)\n",
    "    σ = Dict{Int,Vector{Float64}}(); # noise in utility calculation (unknown to bandits)\n",
    "    B = 100.0; # max budget (unknown to bandits)\n",
    "    C = Dict{Int,Vector{Float64}}(); # unit costs of goods (unknown to bandits)\n",
    "    λ = 0.0; # sensitivity to the budget constraint λ ≥ 0. If zero, then no penalty for budget constraint violation.\n",
    "    Z = Dict{Int,Normal}(); # noise model\n",
    "    number_of_categories = 3; # number of categories\n",
    "\n",
    "    # set the parameters -\n",
    "    # preferences: If all γ[i] are equal to 1.0, then the bandit will be indifferent to the goods in each category.\n",
    "    γ[1] = [1.0, 1.0, 1.0]; # category 1 \n",
    "    γ[2] = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]; # category 2\n",
    "    γ[3] = [1.0, 1.0, 1.0, 1.0]; # category 3\n",
    "\n",
    "    # uncertainty\n",
    "    σ[1] = [0.1, 0.1, 0.1]; # category 1\n",
    "    σ[2] = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1]; # category 2\n",
    "    σ[3] = [0.1, 0.1, 0.1, 0.1]; # category 3\n",
    "\n",
    "    # costs\n",
    "    C[1] = [10.0, 20.0, 30.0]; # category 1\n",
    "    C[2] = [10.0, 20.0, 30.0, 40.0, 50.0, 60.0]; # category 2\n",
    "    C[3] = [10.0, 20.0, 30.0, 40.0]; # category 3\n",
    "\n",
    "    # noise model\n",
    "    Z[1] = Normal(0.0, 1.0); # category 1\n",
    "    Z[2] = Normal(0.0, 1.0); # category 2\n",
    "    Z[3] = Normal(0.0, 1.0); # category 3\n",
    "\n",
    "    # build a context model with the reqired parameters -\n",
    "    context = build(MyBanditConsumerContextModel, (\n",
    "        γ = γ, # consumer preferences (unknown to bandits)\n",
    "        σ = σ, # noise in utility calculation (unknown to bandits)\n",
    "        B = B, # max budget (unknown to bandits)\n",
    "        C = C, # unit costs of goods (unknown to bandits)\n",
    "        λ = λ, # sensitivity to the budget\n",
    "        Z = Z, # noise model\n",
    "        m = number_of_categories\n",
    "    )); # build the context\n",
    "\n",
    "    # return \n",
    "    context;\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b29efc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_with_budget_context = let\n",
    "\n",
    "    # initialize -\n",
    "    γ = Dict{Int,Vector{Float64}}(); # consumer preferences (unknown to bandits)\n",
    "    σ = Dict{Int,Vector{Float64}}(); # noise in utility calculation (unknown to bandits)\n",
    "    B = 100.0; # max budget (unknown to bandits)\n",
    "    C = Dict{Int,Vector{Float64}}(); # unit costs of goods (unknown to bandits)\n",
    "    λ = 100.0; # sensitivity to the budget constraint λ ≥ 0. If zero, then no penalty for budget constraint violation.\n",
    "    Z = Dict{Int,Normal}(); # noise model\n",
    "    number_of_categories = 3; # number of categories\n",
    "\n",
    "    # set the parameters -\n",
    "    # preferences: If all γ[i] are equal to 1.0, then the bandit will be indifferent to the goods in each category.\n",
    "    γ[1] = [1.0, 2.0, 3.0]; # category 1 \n",
    "    γ[2] = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]; # category 2\n",
    "    γ[3] = [1.0, 2.0, 3.0, 4.0]; # category 3\n",
    "\n",
    "    # uncertainty\n",
    "    σ[1] = [0.1, 0.1, 0.1]; # category 1\n",
    "    σ[2] = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1]; # category 2\n",
    "    σ[3] = [0.1, 0.1, 0.1, 0.1]; # category 3\n",
    "\n",
    "    # costs\n",
    "    C[1] = [10.0, 20.0, 30.0]; # category 1\n",
    "    C[2] = [10.0, 20.0, 30.0, 40.0, 50.0, 60.0]; # category 2\n",
    "    C[3] = [10.0, 20.0, 30.0, 40.0]; # category 3\n",
    "\n",
    "    # noise model\n",
    "    Z[1] = Normal(0.0, 1.0); # category 1\n",
    "    Z[2] = Normal(0.0, 1.0); # category 2\n",
    "    Z[3] = Normal(0.0, 1.0); # category 3\n",
    "\n",
    "    # build a context model with the reqired parameters -\n",
    "    context = build(MyBanditConsumerContextModel, (\n",
    "        γ = γ, # consumer preferences (unknown to bandits)\n",
    "        σ = σ, # noise in utility calculation (unknown to bandits)\n",
    "        B = B, # max budget (unknown to bandits)\n",
    "        C = C, # unit costs of goods (unknown to bandits)\n",
    "        λ = λ, # sensitivity to the budget\n",
    "        Z = Z, # noise model\n",
    "        m = number_of_categories\n",
    "    )); # build the context\n",
    "\n",
    "    # return \n",
    "    context;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8680fd-798b-439d-ae82-e50dab5bd4b1",
   "metadata": {},
   "source": [
    "## Task 3: Evaluation of Scenarios\n",
    "In this task, we'll run different context models to evaluate how well our agent performs under different scenarios. This will help us understand how the choice of context model affects the agent's performance and the regret it incurs over time. \n",
    "\n",
    "In all cases, we will use the same agent and bandit algorithm but vary the context model to see how it influences the agent's decisions and performance. We'll use the $\\epsilon$-greedy algorithm to estimate an optimal policy for the agent based on the contextual information provided by the `MyBanditConsumerContextModel`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a98322",
   "metadata": {},
   "source": [
    "__What does the modified algorithm produce__? Let's build a table to see that choices that the bandits in each category are making. `Unhide` the code-block below to see how we construct the simulation results table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac245eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== ======== ======= ========= ========== ========== =========== ==========\n",
      " \u001b[1m category \u001b[0m \u001b[1m action \u001b[0m \u001b[1m    γᵢ \u001b[0m \u001b[1m       n \u001b[0m \u001b[1m unitcost \u001b[0m \u001b[1m cumspend \u001b[0m \u001b[1m remaining \u001b[0m \u001b[1m       U \u001b[0m\n",
      " \u001b[90m    Int64 \u001b[0m \u001b[90m  Int64 \u001b[0m \u001b[90m Int64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m  Float64 \u001b[0m \u001b[90m  Float64 \u001b[0m \u001b[90m   Float64 \u001b[0m \u001b[90m Float64 \u001b[0m\n",
      "=========== ======== ======= ========= ========== ========== =========== ==========\n",
      "         1        3       1       1.0       30.0       30.0        70.0       1.0\n",
      "         2        4       1       2.0       40.0      110.0       -10.0       3.0\n",
      "         3        1       1       3.0       10.0      140.0       -40.0       6.0\n",
      "=========== ======== ======= ========= ========== ========== =========== ==========\n"
     ]
    }
   ],
   "source": [
    " let\n",
    "    results_case_1 = solve(algorithm, T = T, world = world, context=simple_no_budget_context);\n",
    "    table(results_case_1, algorithm, simple_no_budget_context) |> df -> pretty_table(df, tf = tf_simple)\n",
    " end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "585f5e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== ======== ======= ========= ========== ========== =========== ==========\n",
      " \u001b[1m category \u001b[0m \u001b[1m action \u001b[0m \u001b[1m    γᵢ \u001b[0m \u001b[1m       n \u001b[0m \u001b[1m unitcost \u001b[0m \u001b[1m cumspend \u001b[0m \u001b[1m remaining \u001b[0m \u001b[1m       U \u001b[0m\n",
      " \u001b[90m    Int64 \u001b[0m \u001b[90m  Int64 \u001b[0m \u001b[90m Int64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m  Float64 \u001b[0m \u001b[90m  Float64 \u001b[0m \u001b[90m   Float64 \u001b[0m \u001b[90m Float64 \u001b[0m\n",
      "=========== ======== ======= ========= ========== ========== =========== ==========\n",
      "         1        1       1       1.0       10.0       10.0        90.0       1.0\n",
      "         2        3       3       2.0       30.0       70.0        30.0       7.0\n",
      "         3        1       1       3.0       10.0      100.0         0.0      10.0\n",
      "=========== ======== ======= ========= ========== ========== =========== ==========\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    results_case_2 = solve(algorithm, T = T, world = world, context=simple_with_budget_context);\n",
    "    table(results_case_2, algorithm, simple_with_budget_context) |> df -> pretty_table(df, tf = tf_simple)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c9b97f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.4",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
